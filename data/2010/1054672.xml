<?xml version="1.0" encoding="UTF-8"?>

<rootTag>
  <Award>
    <AwardTitle>CAREER: Smart Cameras Getting Smarter: Detecting High-level Events Across Battery-powered Wireless Embedded Smart Cameras</AwardTitle>
    <AwardEffectiveDate>08/01/2011</AwardEffectiveDate>
    <AwardExpirationDate>04/30/2012</AwardExpirationDate>
    <AwardAmount>223316</AwardAmount>
    <AwardInstrument>
      <Value>Continuing grant</Value>
    </AwardInstrument>
    <Organization>
      <Code>05050000</Code>
      <Directorate>
        <LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
      </Directorate>
      <Division>
        <LongName>Division Of Computer and Network Systems</LongName>
      </Division>
    </Organization>
    <ProgramOfficer>
      <SignBlockName>D. Helen Gill</SignBlockName>
    </ProgramOfficer>
    <AbstractNarration>Visual surveillance is widely used in military and commercial applications, and public transportation scenarios. There are an estimated 30 million surveillance cameras in the U.S. capturing 4 billion hours of footage a week. The large amounts of video data generated by these cameras necessitate automatic detection of semantically high-level events, since the attention of a human operator watching multiple video feeds decreases over time. In addition, requiring cameras to have access to electrical outlets and to have wired links hinders system flexibility in terms of the number and placement of cameras, incurs significant costs, and limits possible applications and mobility. Embedded smart cameras allow us to deploy many spatially-distributed cameras interconnected by wireless links. A smart camera combines sensing, processing, and communication on a single embedded platform. Yet, it has very limited energy and processing power. The objective in this project is to build a battery-powered, self-adapting, wireless embedded smart camera system for the detection of semantically high-level events, which can span multiple overlapping or non-overlapping camera views, in a scalable and energy-efficient manner, and remove the dependence on wired links. Resource-aware and distributed object tracking and event detection algorithms, and self-adapting decision methodologies will be developed to decrease the energy consumption, and increase the battery-life of cameras. &lt;br/&gt;&lt;br/&gt;The outcomes are expected to have important positive impact, because they will fundamentally transform video surveillance and event detection solutions by addressing the privacy issues simultaneously. This technology can be used across disciplines and in wide-ranging areas, including next-generation cyber-physical systems, military and commercial applications, traffic analysis, health care and wildlife monitoring. Outreach to younger children is planned through the deployment of this project at the local Children?s Zoo and Museum.</AbstractNarration>
    <MinAmdLetterDate>08/06/2011</MinAmdLetterDate>
    <MaxAmdLetterDate>08/06/2011</MaxAmdLetterDate>
    <ARRAAmount/>
    <AwardID>1054672</AwardID>
    <Investigator>
      <FirstName>Senem</FirstName>
      <LastName>Velipasalar</LastName>
      <EmailAddress>svelipas@syr.edu</EmailAddress>
      <StartDate>08/06/2011</StartDate>
      <EndDate/>
      <RoleCode>Principal Investigator</RoleCode>
    </Investigator>
    <Institution>
      <Name>University of Nebraska-Lincoln</Name>
      <CityName>Lincoln</CityName>
      <ZipCode>685031435</ZipCode>
      <PhoneNumber>4024723171</PhoneNumber>
      <StreetAddress>2200 Vine St, 151 Whittier</StreetAddress>
      <CountryName>United States</CountryName>
      <StateName>Nebraska</StateName>
      <StateCode>NE</StateCode>
    </Institution>
    <ProgramElement>
      <Code>7354</Code>
      <Text>COMPUTER SYSTEMS</Text>
    </ProgramElement>
    <ProgramElement>
      <Code>9150</Code>
      <Text>EXP PROG TO STIM COMP RES</Text>
    </ProgramElement>
    <ProgramReference>
      <Code>1045</Code>
      <Text>CAREER: FACULTY EARLY CAR DEV</Text>
    </ProgramReference>
    <ProgramReference>
      <Code>1187</Code>
      <Text>PECASE- eligible</Text>
    </ProgramReference>
    <ProgramReference>
      <Code>7354</Code>
      <Text>COMPUTER SYSTEMS</Text>
    </ProgramReference>
    <ProgramReference>
      <Code>9102</Code>
      <Text>WOMEN, MINORITY, DISABLED, NEC</Text>
    </ProgramReference>
    <ProgramReference>
      <Code>9150</Code>
      <Text>EXP PROG TO STIM COMP RES</Text>
    </ProgramReference>
  </Award>
</rootTag>
