<?xml version="1.0" encoding="UTF-8"?>

<rootTag>
  <Award>
    <AwardTitle>CAREER: Entropy Geometry in Variational Inference Signal Processing</AwardTitle>
    <AwardEffectiveDate>07/01/2011</AwardEffectiveDate>
    <AwardExpirationDate>06/30/2016</AwardExpirationDate>
    <AwardAmount>507875</AwardAmount>
    <AwardInstrument>
      <Value>Standard Grant</Value>
    </AwardInstrument>
    <Organization>
      <Code>05010000</Code>
      <Directorate>
        <LongName>Directorate for Computer &amp; Information Science &amp; Engineering</LongName>
      </Directorate>
      <Division>
        <LongName>Division of Computer and Communication Foundations</LongName>
      </Division>
    </Organization>
    <ProgramOfficer>
      <SignBlockName>John Cozzens</SignBlockName>
    </ProgramOfficer>
    <AbstractNarration>The past decade has proven that variational approaches to approximate Bayesian inference hold&lt;br/&gt;the key to pragmatic solutions to many signal processing problems previously thought to be fundamentally difficult. Important signal processing problems where the application of appropriate&lt;br/&gt;variational approximate Bayesian inference techniques led to significant breakthroughs include the decoding of capacity approaching codes for noisy channels, underdetermined speech source separation, and distributed estimation over networks. These applications provide evidence that variational inference techniques have revolutionized the state of the art in signal processing because of their ability to provide high performance estimates at reasonable complexity and communication (equivalently, energy consumption) costs. However, the tradeoff between their performance and required complexity and communication, the very phenomenon leading to their widespread and growing adoption, remains incompletely understood.&lt;br/&gt;&lt;br/&gt;The underlying thesis of this project is that entropy &amp; information geometry lies at the heart&lt;br/&gt;of the tradeo ff between performance, complexity, and communication in variational inference based&lt;br/&gt;signal processing. The research being performed improves our understanding of entropy geometry,&lt;br/&gt;which primarily dictates the fundamental relationship between the performance of a collaborative&lt;br/&gt;estimation algorithm and its communication cost. This research also develops the information geometric relationship between a variational inference signal processing technique's performance and&lt;br/&gt;complexity. Together, these insights allow algorithms for robust speech processing and collaborative estimation over networks to be developed that provide optimal performance at a tunable complexity and communication cost. In addition to its benefits in each of these areas, the work has a synergistic aspect in that it contributes directly to the creation of an overall design science for&lt;br/&gt;efficient distributed variational inference signal processing algorithms.</AbstractNarration>
    <MinAmdLetterDate>06/14/2011</MinAmdLetterDate>
    <MaxAmdLetterDate>07/28/2011</MaxAmdLetterDate>
    <ARRAAmount/>
    <AwardID>1053702</AwardID>
    <Investigator>
      <FirstName>John</FirstName>
      <LastName>Walsh</LastName>
      <EmailAddress>jwalsh@ece.drexel.edu</EmailAddress>
      <StartDate>06/14/2011</StartDate>
      <EndDate/>
      <RoleCode>Principal Investigator</RoleCode>
    </Investigator>
    <Institution>
      <Name>Drexel University</Name>
      <CityName>Philadelphia</CityName>
      <ZipCode>191042875</ZipCode>
      <PhoneNumber>2158955849</PhoneNumber>
      <StreetAddress>3201 Arch Street</StreetAddress>
      <CountryName>United States</CountryName>
      <StateName>Pennsylvania</StateName>
      <StateCode>PA</StateCode>
    </Institution>
  </Award>
</rootTag>
