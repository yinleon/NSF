<?xml version="1.0" encoding="UTF-8"?>

<rootTag>
  <Award>
    <AwardTitle>EAGER: Modeling Interpretive Argument with Case Analogies and Rules in Ill-Defined Domains</AwardTitle>
    <AwardEffectiveDate>09/01/2010</AwardEffectiveDate>
    <AwardExpirationDate>08/31/2012</AwardExpirationDate>
    <AwardAmount>50000</AwardAmount>
    <AwardInstrument>
      <Value>Standard Grant</Value>
    </AwardInstrument>
    <Organization>
      <Code>05020000</Code>
      <Directorate>
        <LongName>Directorate for Computer &amp; Information Science &amp; Engineering</LongName>
      </Directorate>
      <Division>
        <LongName>Division of Information &amp; Intelligent Systems</LongName>
      </Division>
    </Organization>
    <ProgramOfficer>
      <SignBlockName>Tatiana D. Korelsky</SignBlockName>
    </ProgramOfficer>
    <AbstractNarration>In ill-defined domains such as engineering design and ethics, mathematical discovery, and law, problems often have more than one 'right' answer. In such situations decision-makers propose rules or hypotheses about how to decide the problem in light of past cases and underlying principles and policies; through this process of interpretive argument decision-makers may then pose hypothetical examples in order to draw out and test the normative, logical, or empirical consequences of the hypothesis. &lt;br/&gt;&lt;br/&gt;In integrating decision rules, case analogies, hypothetical examples, underlying principles, and policies, interpretive argument is a paradigm of robust reasoning. Although the problems are ill-defined, interpretive argument has an underlying logic, which this project is modeling computationally. By working in successively more complex argument microworlds, families of cases, rules, concepts, principles and policies drawn from realistic legal domains, the project is developing an ontology and implementing inference control mechanisms and argument schema with which a computer program will engage in interpretive argument. Empirical evaluation of the computational model is comparing arguments by the computer and by human arguers.&lt;br/&gt;&lt;br/&gt;The work contributes to the fields of AI, argumentation theory, AI and Law, and case-based reasoning, and it aims in the longer term to contribute to intelligent tutoring systems that will prepare students for making effective, supportable and otherwise rational arguments, and to design artificial agents as proxies and advocates for humans engaged in disputes.</AbstractNarration>
    <MinAmdLetterDate>07/19/2010</MinAmdLetterDate>
    <MaxAmdLetterDate>07/19/2010</MaxAmdLetterDate>
    <ARRAAmount/>
    <AwardID>1049414</AwardID>
    <Investigator>
      <FirstName>Kevin</FirstName>
      <LastName>Ashley</LastName>
      <EmailAddress>ashley@pitt.edu</EmailAddress>
      <StartDate>07/19/2010</StartDate>
      <EndDate/>
      <RoleCode>Principal Investigator</RoleCode>
    </Investigator>
    <Institution>
      <Name>University of Pittsburgh</Name>
      <CityName>Pittsburgh</CityName>
      <ZipCode>152132303</ZipCode>
      <PhoneNumber>4126247400</PhoneNumber>
      <StreetAddress>University Club</StreetAddress>
      <CountryName>United States</CountryName>
      <StateName>Pennsylvania</StateName>
      <StateCode>PA</StateCode>
    </Institution>
  </Award>
</rootTag>
