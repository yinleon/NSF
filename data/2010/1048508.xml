<?xml version="1.0" encoding="UTF-8"?>

<rootTag>
  <Award>
    <AwardTitle>EAGER: Exploring Compressive Sampling for Extreme-Scale Data Visualization</AwardTitle>
    <AwardEffectiveDate>09/01/2010</AwardEffectiveDate>
    <AwardExpirationDate>08/31/2012</AwardExpirationDate>
    <AwardAmount>85000</AwardAmount>
    <AwardInstrument>
      <Value>Standard Grant</Value>
    </AwardInstrument>
    <Organization>
      <Code>05020000</Code>
      <Directorate>
        <LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
      </Directorate>
      <Division>
        <LongName>Div Of Information &amp; Intelligent Systems</LongName>
      </Division>
    </Organization>
    <ProgramOfficer>
      <SignBlockName>Lawrence Rosenblum</SignBlockName>
    </ProgramOfficer>
    <AbstractNarration>Abstract&lt;br/&gt;&lt;br/&gt;This EAGER aims to provide practical evidence of feasibility for a larger project called instance-optimal sampling. The instance-optimal sampling is a foundational framework for optimal representation of extreme-scale (scattered, unstructured, and structured) datasets. Using the dense polytope packing algorithms, the instance-optimal sampling framework develops strategies for sampling a given dataset at the optimally minimal sampling rate. The instance-optimal representation is derived based on the multidimensional notion of Nyquist frequencies; therefore, this approach is best complemented with the compressive sampling (CS) methods that exploit the sparsity of a dataset to reduce the sampling rate significantly below the Nyquist rate with no loss of information.&lt;br/&gt;&lt;br/&gt;The main motivation in this research is that the synergy of compressive sampling and instance-optimal sampling would potentially allow the reduction of an extreme-scale dataset to sizes that are logarithmically proportional to number of samples in that dataset and linearly proportional to its sparsity. The research addresses the computational efficiency issue of sparse reconstruction for volumetric and time-varying datasets, which can lay the basis for applying CS to computer graphics problems. The main challenge is the computational cost of the reconstruction algorithm for 3-D or time-varying data. This research examines the feasibility of adopting a tensor-product approach to compressive sampling.</AbstractNarration>
    <MinAmdLetterDate>08/24/2010</MinAmdLetterDate>
    <MaxAmdLetterDate>08/24/2010</MaxAmdLetterDate>
    <ARRAAmount/>
    <AwardID>1048508</AwardID>
    <Investigator>
      <FirstName>Alireza</FirstName>
      <LastName>Entezari</LastName>
      <EmailAddress>entezari@cise.ufl.edu</EmailAddress>
      <StartDate>08/24/2010</StartDate>
      <EndDate/>
      <RoleCode>Principal Investigator</RoleCode>
    </Investigator>
    <Institution>
      <Name>University of Florida</Name>
      <CityName>GAINESVILLE</CityName>
      <ZipCode>326112002</ZipCode>
      <PhoneNumber>3523923516</PhoneNumber>
      <StreetAddress>1 UNIVERSITY OF FLORIDA</StreetAddress>
      <CountryName>United States</CountryName>
      <StateName>Florida</StateName>
      <StateCode>FL</StateCode>
    </Institution>
    <ProgramElement>
      <Code>7367</Code>
      <Text>Cyber-Human Systems (CHS)</Text>
    </ProgramElement>
    <ProgramReference>
      <Code>7916</Code>
      <Text>EAGER</Text>
    </ProgramReference>
  </Award>
</rootTag>
