<?xml version="1.0" encoding="UTF-8"?>

<rootTag>
  <Award>
    <AwardTitle>Collaborative Research: Forecast Evaluation and Model Selection in the Presence of Structural Instability</AwardTitle>
    <AwardEffectiveDate>07/01/2009</AwardEffectiveDate>
    <AwardExpirationDate>02/28/2011</AwardExpirationDate>
    <AwardAmount>79474</AwardAmount>
    <AwardInstrument>
      <Value>Continuing grant</Value>
    </AwardInstrument>
    <Organization>
      <Code>04050100</Code>
      <Directorate>
        <LongName>Direct For Social, Behav &amp; Economic Scie</LongName>
      </Directorate>
      <Division>
        <LongName>Divn Of Social and Economic Sciences</LongName>
      </Division>
    </Organization>
    <ProgramOfficer>
      <SignBlockName>Nancy A. Lutz</SignBlockName>
    </ProgramOfficer>
    <AbstractNarration>The widespread empirical findings of instabilities in macroeconomic and financial data have attracted a lot of attention recently. As a result, much effort has been devoted to designing new and improved tests for parameter instability, and researchers have paid more attention to such tools in their empirical work. However, methods that allow forecast model evaluation and selection in such unstable environments are still lacking in the literature. It is therefore important to develop such tools, and the investigators' research agenda aims at filling that void. The investigators' propose to investigate new methods for evaluating the forecasting performance of economic models, and for conducting model selection in the presence of structural instability. The novelty of their approach is to allow for unstable environments where the forecasting performance of a model, as well as the relative performance of competing models, could be changing over time.&lt;br/&gt;&lt;br/&gt;In the first subproject, Detecting and Predicting Forecast Breakdowns, the investigators propose to investigate a theoretical framework for assessing whether a forecast model estimated over one period can provide good forecasts over a subsequent period. They define a forecast breakdown as a situation in which the out-of-sample performance of the model, judged by some loss function, is significantly worse than its in-sample performance, and propose a method to detect such situations. In a second research project, Non-nested Model Selection in Unstable Environments, the investigators plan to consider non-nested model selection tests in the presence of possible data and parameter instabilities. The novelty of their approach is that it allows the models' relative performance to be varying over time, whereas existing model selection techniques look for an overall best model. &lt;br/&gt;&lt;br/&gt;The broader impact of the proposed activity will come from the new methods shared with practitioners within the scientific community and students alike, and the contributions to our understanding the role of instabilities in economics. This project provides mentoring, collaboration opportunity, dissertation motivation and financial support for a graduate student. The proposal will result in papers that will be presented at seminars and professional conferences, and ultimately published in scholarly journals.</AbstractNarration>
    <MinAmdLetterDate>12/03/2009</MinAmdLetterDate>
    <MaxAmdLetterDate>12/03/2009</MaxAmdLetterDate>
    <ARRAAmount/>
    <AwardID>1011065</AwardID>
    <Investigator>
      <FirstName>Raffaella</FirstName>
      <LastName>Giacomini</LastName>
      <EmailAddress>r.giacomini@ucl.ac.uk</EmailAddress>
      <StartDate>12/03/2009</StartDate>
      <EndDate/>
      <RoleCode>Principal Investigator</RoleCode>
    </Investigator>
    <Institution>
      <Name>University of California-San Diego</Name>
      <CityName>La Jolla</CityName>
      <ZipCode>920930934</ZipCode>
      <PhoneNumber>8585344896</PhoneNumber>
      <StreetAddress>Office of Contract &amp; Grant Admin</StreetAddress>
      <CountryName>United States</CountryName>
      <StateName>California</StateName>
      <StateCode>CA</StateCode>
    </Institution>
    <ProgramElement>
      <Code>1320</Code>
      <Text>ECONOMICS</Text>
    </ProgramElement>
    <ProgramElement>
      <Code>1333</Code>
      <Text>METHOD, MEASURE &amp; STATS</Text>
    </ProgramElement>
    <ProgramReference>
      <Code>0000</Code>
      <Text>UNASSIGNED</Text>
    </ProgramReference>
    <ProgramReference>
      <Code>1320</Code>
      <Text>ECONOMICS</Text>
    </ProgramReference>
    <ProgramReference>
      <Code>OTHR</Code>
      <Text>OTHER RESEARCH OR EDUCATION</Text>
    </ProgramReference>
  </Award>
</rootTag>
