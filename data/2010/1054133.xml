<?xml version="1.0" encoding="UTF-8"?>

<rootTag>
  <Award>
    <AwardTitle>CAREER: Toward a General Framework for Words and Pictures</AwardTitle>
    <AwardEffectiveDate>06/01/2011</AwardEffectiveDate>
    <AwardExpirationDate>06/30/2014</AwardExpirationDate>
    <AwardAmount>269605</AwardAmount>
    <AwardInstrument>
      <Value>Continuing grant</Value>
    </AwardInstrument>
    <Organization>
      <Code>05020000</Code>
      <Directorate>
        <LongName>Directorate for Computer &amp; Information Science &amp; Engineering</LongName>
      </Directorate>
      <Division>
        <LongName>Division of Information &amp; Intelligent Systems</LongName>
      </Division>
    </Organization>
    <ProgramOfficer>
      <SignBlockName>Jie Yang</SignBlockName>
    </ProgramOfficer>
    <AbstractNarration>Pictures convey a visual description of the world directly to their viewers. Computer vision strives to design algorithms to extract the underlying world state captured in the camera's eye, with an overarching goal of general computational image understanding. To date much vision research has approached image understanding by focusing on object detection, only one perspective on the image understanding problem. This project looks at an additional, complimentary way to collect information about the visual world -- by directly analyzing the enormous amount of visually descriptive text on the web to reveal what information is useful to attach to, and extract from pictures. This project presents a comprehensive research program geared toward modeling and exploiting the complimentary nature of words and pictures. One main goal is studying the connection between text and images to learn about depiction -- communication of meaning through pictures. This goal is addressed through 3 broad challenges: 1) Developing a richer vocabulary to describe the information provided by depiction. 2) Developing image representations that can visually capture this more nuanced vocabulary. 3) Constructing a comprehensive joint words and pictures framework. &lt;br/&gt;&lt;br/&gt;This project has direct significance to many concrete tasks that access images on the internet including: image search, browsing, and organization, as well as commercial applications such as product search, and societally important applications such as web assistance for the blind. Additionally, outputs of this project, including progress toward a natural vocabulary and structure for visual description, have great potential for cross-cutting impact in both the computer vision and natural language communities.</AbstractNarration>
    <MinAmdLetterDate>01/10/2011</MinAmdLetterDate>
    <MaxAmdLetterDate>06/03/2013</MaxAmdLetterDate>
    <ARRAAmount/>
    <AwardID>1054133</AwardID>
    <Investigator>
      <FirstName>Tamara</FirstName>
      <LastName>Berg</LastName>
      <EmailAddress>tlberg@cs.unc.edu</EmailAddress>
      <StartDate>01/10/2011</StartDate>
      <EndDate/>
      <RoleCode>Principal Investigator</RoleCode>
    </Investigator>
    <Institution>
      <Name>SUNY at Stony Brook</Name>
      <CityName>STONY BROOK</CityName>
      <ZipCode>117943362</ZipCode>
      <PhoneNumber>6316329949</PhoneNumber>
      <StreetAddress>WEST 5510 FRK MEL LIB</StreetAddress>
      <CountryName>United States</CountryName>
      <StateName>New York</StateName>
      <StateCode>NY</StateCode>
    </Institution>
  </Award>
</rootTag>
