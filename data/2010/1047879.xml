<?xml version="1.0" encoding="UTF-8"?>

<rootTag>
  <Award>
    <AwardTitle>SI2-SSI: Accelerating the Pace of Research through Implicitly Parallel Programming</AwardTitle>
    <AwardEffectiveDate>10/01/2010</AwardEffectiveDate>
    <AwardExpirationDate>03/31/2016</AwardExpirationDate>
    <AwardAmount>1740214</AwardAmount>
    <AwardInstrument>
      <Value>Standard Grant</Value>
    </AwardInstrument>
    <Organization>
      <Code>05090000</Code>
      <Directorate>
        <LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
      </Directorate>
      <Division>
        <LongName>Div Of Advanced Cyberinfrastructure</LongName>
      </Division>
    </Organization>
    <ProgramOfficer>
      <SignBlockName>Sol J. Greenspan</SignBlockName>
    </ProgramOfficer>
    <AbstractNarration>Today, two trends conspire to slow down the pace of science, engineering, and academic research progress in general. First, researchers increasingly rely on computation to process ever larger data sets and to perform ever more computationally-intensive simulations. Second, individual processor speeds are no longer increasing with every computer chip generation as they once were. To compensate, processor manufacturers have moved to including more processors, or cores, on a chip with each generation. To obtain peak performance on these multicore chips, software must be implemented so that it can execute in parallel and thereby use the additional processor cores. Unfortunately, writing efficient, explicitly parallel software programs using today's software-development tools takes advanced training in computer science, and even with such training, the task remains extremely difficult, error-prone, and time consuming. This project will create a new high-level programming platform, called Implicit Parallel Programming (IPP), designed to bring the performance promises of modern multicore machines to scientists and engineers without the costs associated with having to teach these users how to write explicitly parallel programs. In the short term, this research will provide direct and immediate benefit to researchers in several areas of science as the PIs will pair computer science graduate students with non-computer science graduate students to study, analyze, and develop high-value scientific applications. In the long term, this research has the potential to fundamentally change the way scientists obtain performance from parallel machines, improve their productivity, and accelerate the overall pace of science. This work will also have major educational impact by developing courseware and tutorial materials, useable by all scientists and engineers, on the topics of explicit and implicit parallel computing.&lt;br/&gt;&lt;br/&gt;IPP will operate by allowing users to write ordinary sequential programs and then to augment them with logical specifications that expand (or abstract) the set of sequential program behaviors. This capacity for abstraction will provide parallelizing compilers with the flexibility to more aggressively optimize programs than would otherwise be possible. In fact, it will enable effective parallelization techniques where they were impossible before. The language design and compiler implementation will be accompanied by formal semantic analysis that will be used to judge the correctness of compiler transformations, provide a foundation for about reasoning programs, and guide the creation of static analysis and program defect detection algorithms. Moreover since existing programs and languages can be viewed as (degenerately) implicitly parallel, decades of investment in human expertise, languages, compilers, methods, tools, and applications is preserved. In particular, it will be possible to upgrade old legacy programs or libraries from slow sequential versions without overhauling the entire system architecture, but merely by adding a few auxiliary specifications. Compiler technology will help guide scientists and engineers through this process, further simplifying the task. Conceptually, IPP restores an important layer of abstraction, freeing programmers to write high-level code, designed to be easy to understand, rather than low-level code, architected according to the specific demands of a particular parallel machine.</AbstractNarration>
    <MinAmdLetterDate>09/13/2010</MinAmdLetterDate>
    <MaxAmdLetterDate>09/13/2010</MaxAmdLetterDate>
    <ARRAAmount/>
    <AwardID>1047879</AwardID>
    <Investigator>
      <FirstName>David</FirstName>
      <LastName>August</LastName>
      <EmailAddress>august@cs.princeton.edu</EmailAddress>
      <StartDate>09/13/2010</StartDate>
      <EndDate/>
      <RoleCode>Principal Investigator</RoleCode>
    </Investigator>
    <Investigator>
      <FirstName>David</FirstName>
      <LastName>Walker</LastName>
      <EmailAddress>dpw@cs.princeton.edu</EmailAddress>
      <StartDate>09/13/2010</StartDate>
      <EndDate/>
      <RoleCode>Co-Principal Investigator</RoleCode>
    </Investigator>
    <Institution>
      <Name>Princeton University</Name>
      <CityName>Princeton</CityName>
      <ZipCode>085442020</ZipCode>
      <PhoneNumber>6092583090</PhoneNumber>
      <StreetAddress>Off. of Research &amp; Proj. Admin.</StreetAddress>
      <CountryName>United States</CountryName>
      <StateName>New Jersey</StateName>
      <StateCode>NJ</StateCode>
    </Institution>
    <ProgramElement>
      <Code>1640</Code>
      <Text>INFORMATION TECHNOLOGY RESEARC</Text>
    </ProgramElement>
    <ProgramElement>
      <Code>2878</Code>
      <Text>SPECIAL PROJECTS - CCF</Text>
    </ProgramElement>
    <ProgramElement>
      <Code>8004</Code>
      <Text>Software Institutes</Text>
    </ProgramElement>
    <ProgramReference>
      <Code>1640</Code>
      <Text>INFORMATION TECHNOLOGY RESEARC</Text>
    </ProgramReference>
    <ProgramReference>
      <Code>2878</Code>
      <Text>SPECIAL PROJECTS - CCF</Text>
    </ProgramReference>
  </Award>
</rootTag>
