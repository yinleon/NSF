<?xml version="1.0" encoding="UTF-8"?>

<rootTag>
  <Award>
    <AwardTitle>Planned Missing Research Designs: Power and Validity of Planned Missing Data Designs in Longitudinal Research</AwardTitle>
    <AwardEffectiveDate>06/15/2011</AwardEffectiveDate>
    <AwardExpirationDate>05/31/2016</AwardExpirationDate>
    <AwardAmount>400026</AwardAmount>
    <AwardInstrument>
      <Value>Standard Grant</Value>
    </AwardInstrument>
    <Organization>
      <Code>04040000</Code>
      <Directorate>
        <LongName>Direct For Social, Behav &amp; Economic Scie</LongName>
      </Directorate>
      <Division>
        <LongName>Division Of Behavioral and Cognitive Sci</LongName>
      </Division>
    </Organization>
    <ProgramOfficer>
      <SignBlockName>Laura Namy</SignBlockName>
    </ProgramOfficer>
    <AbstractNarration>This project will develop and evaluate a research methodology known as a "planned missing research design." This statistical technique enables scientists who conduct longitudinal studies to obtain higher quality results (greater statistical certainty and/or broader ability to generalize findings) using the same amount of research resources. This technique has been used with great effectiveness in certain specific contexts in the past. The proposed project will provide guidelines and procedures that will enable researchers to use the technique in all areas of developmental science in which a study evaluates how participants change over time.&lt;br/&gt;&lt;br/&gt;Planned missing data designs have tremendous potential to streamline how we conduct basic research in the social, behavioral, and educational sciences. Strong statistical theory supports the idea that carefully planned patterns of intentionally missing information will not bias or weaken the accuracy of research conclusions. When properly constructed a planned missing design can save 33% or more of the costs associated with data collection. They can also reduce the fatigue and demand on participants which can increase the overall quality of the data that is collected from each participant. In fact, planned missing research designs have been recommended for decades as efficient ways to collect expensive data (e.g., one-on-one assessments) and time-intensive data (e.g., large questionnaire protocols and repeated measures). Planned missing data designs can be used to manage cost, improve data quality, reduce fatigue of participants and test-retest effect, as well as increase statistical power to detect effects of interest. Statisticians are certain of these benefits; researchers and stakeholders, however, remain skeptical. Outside the ideal conditions that statisticians espouse for such designs, are they practical for the conditions faced in real-world research? Statistical proofs are just a starting point for answering important questions about the practical nature of these designs. This research will provide compelling guidance to researchers for using planned missing research designs in social, behavioral, and educational research.&lt;br/&gt;&lt;br/&gt;To validate their utility for practical researchers, planned missing designs will be thoroughly studied under varying conditions of real-world data. The goal of this sponsored research is to examine precisely under what conditions such designs can be useful and the conditions in which caution would be warranted. Previous studies on planned missing data designs have all been small scale simulation studies that demonstrate proof of concept but do not provide practical guidance to researchers. This funded project will conduct a series of well-conceived large-scale Monte Carlo simulation studies to explore the utility of planned missing data designs under a wide variety of conditions including extreme data conditions and complex longitudinal designs. This project will vary the critical features of planned missing designs that will inform researchers on when, how, and why to use planned missing elements in their research designs. The results of this project fully detail the boundaries of when this design is useful and when it should be avoided or modified. By so doing, the results of this work will be paradigm shifting for research across the social, behavioral, and educational sciences because real-world researchers and stakeholders will now understand their utility and applicability. As a result, this funded project will impact and change the future of best-practice methodology in all these research areas.</AbstractNarration>
    <MinAmdLetterDate>06/14/2011</MinAmdLetterDate>
    <MaxAmdLetterDate>06/07/2014</MaxAmdLetterDate>
    <ARRAAmount/>
    <AwardID>1053160</AwardID>
    <Investigator>
      <FirstName>Todd</FirstName>
      <LastName>Little</LastName>
      <EmailAddress>yhat@ttu.edu</EmailAddress>
      <StartDate>06/14/2011</StartDate>
      <EndDate/>
      <RoleCode>Co-Principal Investigator</RoleCode>
    </Investigator>
    <Investigator>
      <FirstName>Wei</FirstName>
      <LastName>Wu</LastName>
      <EmailAddress>wwei@ku.edu</EmailAddress>
      <StartDate>06/14/2011</StartDate>
      <EndDate/>
      <RoleCode>Principal Investigator</RoleCode>
    </Investigator>
    <Institution>
      <Name>University of Kansas Center for Research Inc</Name>
      <CityName>LAWRENCE</CityName>
      <ZipCode>660457568</ZipCode>
      <PhoneNumber>7858643441</PhoneNumber>
      <StreetAddress>2385 IRVING HILL RD</StreetAddress>
      <CountryName>United States</CountryName>
      <StateName>Kansas</StateName>
      <StateCode>KS</StateCode>
    </Institution>
    <ProgramElement>
      <Code>1698</Code>
      <Text>DEVELOP&amp; LEARNING SCIENCES/CRI</Text>
    </ProgramElement>
    <ProgramElement>
      <Code>9150</Code>
      <Text>EXP PROG TO STIM COMP RES</Text>
    </ProgramElement>
    <ProgramReference>
      <Code>1698</Code>
      <Text>DEVELOP&amp; LEARNING SCIENCES/CRI</Text>
    </ProgramReference>
    <ProgramReference>
      <Code>9150</Code>
      <Text>EXP PROG TO STIM COMP RES</Text>
    </ProgramReference>
  </Award>
</rootTag>
