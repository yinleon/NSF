<?xml version="1.0" encoding="UTF-8"?>

<rootTag>
  <Award>
    <AwardTitle>Fast First-Order Methods for Large-Scale Structured and Sparse Optimization</AwardTitle>
    <AwardEffectiveDate>09/01/2010</AwardEffectiveDate>
    <AwardExpirationDate>08/31/2014</AwardExpirationDate>
    <AwardAmount>450000</AwardAmount>
    <AwardInstrument>
      <Value>Standard Grant</Value>
    </AwardInstrument>
    <Organization>
      <Code>03040000</Code>
      <Directorate>
        <LongName>Direct For Mathematical &amp; Physical Scien</LongName>
      </Directorate>
      <Division>
        <LongName>Division Of Mathematical Sciences</LongName>
      </Division>
    </Organization>
    <ProgramOfficer>
      <SignBlockName>Junping Wang</SignBlockName>
    </ProgramOfficer>
    <AbstractNarration>Algorithms for large-scale optimization have traditionally exploited&lt;br/&gt;sparsity and structure in problem data. Many important optimization &lt;br/&gt;problems today, such as those that arise in statistical machine &lt;br/&gt;learning (ML) and in compressive sensing (CS) are extremely large-scale convex&lt;br/&gt;problems with completely dense and/or unstructured problem data. &lt;br/&gt;However, there is often sparsity and structure in the solutions to &lt;br/&gt;these problems. The goal of this research project is the development of&lt;br/&gt;first-order algorithms, including gradient methods for non-smooth functions,&lt;br/&gt;smoothed penalty methods for constrained problems, multiple splitting methods,&lt;br/&gt;alternating-direction augmented-Lagrangian methods, and&lt;br/&gt;block coordinate descent methods, for extremely large-scale convex &lt;br/&gt;optimization problems that take advantage of solution structure and/or &lt;br/&gt;sparsity. Rigorous convergence analysis for these methods will be provided and&lt;br/&gt;robust software implementations will be developed. Although these &lt;br/&gt;methods are expected to have wide applicability, the focus will be on &lt;br/&gt;applications in CS and ML. Specifically, the investigators propose to &lt;br/&gt;develop and analyze new scalable algorithms for (i) CS signal &lt;br/&gt;recovery, including algorithms that are able to exploit more detailed &lt;br/&gt;a priori knowledge in addition to sparsity; (ii) matrix rank minimization, the &lt;br/&gt;matrix analog of CS, and its variants; and (iii) a broad array of ML problems that exploit &lt;br/&gt;the special sparsity/structure of the solutions to these &lt;br/&gt;problems.&lt;br/&gt;&lt;br/&gt;The research that is proposed under this grant is focused on the development of &lt;br/&gt;algorithms with provable performance guarantees that are capable of &lt;br/&gt;solving extremely large scale optimization problems whose solutions are &lt;br/&gt;either sparse or have special structure. Such problems arise under the paradigm of &lt;br/&gt;compressive sensing, which allows signals (e.g., radar) and images &lt;br/&gt;(e.g., CT and MRI scans) to be obtained with far fewer measurements &lt;br/&gt;than predicted by traditional theory, various extensions of CS, and in &lt;br/&gt;a broad array of problems in machine learning. All of these problems are &lt;br/&gt;aimed at extracting a "sparse" or low-dimensional true model from a &lt;br/&gt;high dimensional or dense empirical model or data. They have important applications &lt;br/&gt;in extracting information from surveillance video and hyper-spectral images, face &lt;br/&gt;recognition, medical imaging and data mining,as well as many other areas &lt;br/&gt;of strategic interest such as national security and biotechnology.</AbstractNarration>
    <MinAmdLetterDate>08/16/2010</MinAmdLetterDate>
    <MaxAmdLetterDate>08/16/2010</MaxAmdLetterDate>
    <ARRAAmount/>
    <AwardID>1016571</AwardID>
    <Investigator>
      <FirstName>Donald</FirstName>
      <LastName>Goldfarb</LastName>
      <EmailAddress>goldfarb@columbia.edu</EmailAddress>
      <StartDate>08/16/2010</StartDate>
      <EndDate/>
      <RoleCode>Principal Investigator</RoleCode>
    </Investigator>
    <Investigator>
      <FirstName>Garud</FirstName>
      <LastName>Iyengar</LastName>
      <EmailAddress>garud@ieor.columbia.edu</EmailAddress>
      <StartDate>08/16/2010</StartDate>
      <EndDate/>
      <RoleCode>Co-Principal Investigator</RoleCode>
    </Investigator>
    <Investigator>
      <FirstName>Katya</FirstName>
      <LastName>Scheinberg</LastName>
      <EmailAddress>kas410@lehigh.edu</EmailAddress>
      <StartDate>08/16/2010</StartDate>
      <EndDate/>
      <RoleCode>Co-Principal Investigator</RoleCode>
    </Investigator>
    <Institution>
      <Name>Columbia University</Name>
      <CityName>NEW YORK</CityName>
      <ZipCode>100276902</ZipCode>
      <PhoneNumber>2128546851</PhoneNumber>
      <StreetAddress>2960 Broadway</StreetAddress>
      <CountryName>United States</CountryName>
      <StateName>New York</StateName>
      <StateCode>NY</StateCode>
    </Institution>
    <ProgramElement>
      <Code>1271</Code>
      <Text>COMPUTATIONAL MATHEMATICS</Text>
    </ProgramElement>
    <ProgramElement>
      <Code>5514</Code>
      <Text>OPERATIONS RESEARCH</Text>
    </ProgramElement>
    <ProgramReference>
      <Code>9263</Code>
      <Text>COMPUTATIONAL SCIENCE &amp; ENGING</Text>
    </ProgramReference>
  </Award>
</rootTag>
