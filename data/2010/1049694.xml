<?xml version="1.0" encoding="UTF-8"?>

<rootTag>
  <Award>
    <AwardTitle>III: EAGER: Learning Evaluation Metrics for Information Retrieval</AwardTitle>
    <AwardEffectiveDate>09/01/2010</AwardEffectiveDate>
    <AwardExpirationDate>08/31/2013</AwardExpirationDate>
    <AwardAmount>206000</AwardAmount>
    <AwardInstrument>
      <Value>Standard Grant</Value>
    </AwardInstrument>
    <Organization>
      <Code>05020000</Code>
      <Directorate>
        <LongName>Directorate for Computer &amp; Information Science &amp; Engineering</LongName>
      </Directorate>
      <Division>
        <LongName>Division of Information &amp; Intelligent Systems</LongName>
      </Division>
    </Organization>
    <ProgramOfficer>
      <SignBlockName>Maria Zemankova</SignBlockName>
    </ProgramOfficer>
    <AbstractNarration>Information retrieval (IR) performance is typically measured in terms of relevancy: every document is known to be either relevant or non-relevant to a particular query. Furthermore, more relevant documents are expected to receive a higher rank than lower less relevant documents. However, determination of relevance and rank by users is not practical. Therefore, it is crucial to develop evaluation metrics and ranking functions that can be derived automatically from judgment data and user behavior data, rather than ad-hoc heuristics. This exploratory project investigates machine learning approaches for constructing evaluation metrics for Web search and information retrieval that consider along important directions other than relevance such as diversity, balance and coverage. &lt;br/&gt;&lt;br/&gt;The approach is based on fundamentally extending the popular evaluation metric Discounted Cumulated Gains (DCG). Research focuses on developing optimization methods for learning DCG that can incorporate the degree of difference in pair-wise comparison of ranking lists. Machine learning methods that can learn DCG for the more realistic scenarios where the relevance grades are not readily available are explored, and nonlinear utility functions as evaluation metrics that can accurately capture the quality of search result sets in terms of relevance, diversity, coverage, balance and novelty are investigated.&lt;br/&gt;&lt;br/&gt;The project has a number of broad impacts. Research results are expected to provide foundations for further research in evaluation metrics. Active collaborations with industry leaders in Web search will enable the resulting methods to have real impacts on search engine as well as large IR system performance improvements. Improving the quality of search results will have significant impacts on satisfying people's information needs as well as their quality of life in general. The set of research topics lies at the interface between information retrieval and machine learning applications and it provides an ideal setting for training undergraduate and graduate students in the emerging interdisciplinary field of Web of science and engineering research. The project Web site (http://www.cc.gatech.edu/~zha/metrics.html) will be used for results dissemination.</AbstractNarration>
    <MinAmdLetterDate>08/24/2010</MinAmdLetterDate>
    <MaxAmdLetterDate>03/01/2012</MaxAmdLetterDate>
    <ARRAAmount/>
    <AwardID>1049694</AwardID>
    <Investigator>
      <FirstName>Hongyuan</FirstName>
      <LastName>Zha</LastName>
      <EmailAddress>zha@cc.gatech.edu</EmailAddress>
      <StartDate>08/24/2010</StartDate>
      <EndDate/>
      <RoleCode>Principal Investigator</RoleCode>
    </Investigator>
    <Institution>
      <Name>Georgia Tech Research Corporation</Name>
      <CityName>Atlanta</CityName>
      <ZipCode>303320420</ZipCode>
      <PhoneNumber>4048944819</PhoneNumber>
      <StreetAddress>Office of Sponsored Programs</StreetAddress>
      <CountryName>United States</CountryName>
      <StateName>Georgia</StateName>
      <StateCode>GA</StateCode>
    </Institution>
  </Award>
</rootTag>
