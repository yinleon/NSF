<?xml version="1.0" encoding="UTF-8"?>

<rootTag>
  <Award>
    <AwardTitle>EAGER: Shared Gaze in Collaborative Referring</AwardTitle>
    <AwardEffectiveDate>09/01/2010</AwardEffectiveDate>
    <AwardExpirationDate>08/31/2012</AwardExpirationDate>
    <AwardAmount>100000</AwardAmount>
    <AwardInstrument>
      <Value>Standard Grant</Value>
    </AwardInstrument>
    <Organization>
      <Code>05020000</Code>
      <Directorate>
        <LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
      </Directorate>
      <Division>
        <LongName>Div Of Information &amp; Intelligent Systems</LongName>
      </Division>
    </Organization>
    <ProgramOfficer>
      <SignBlockName>Tatiana D. Korelsky</SignBlockName>
    </ProgramOfficer>
    <AbstractNarration>In situated dialogue, although artificial agents and their human partners are copresent in a shared environment, their knowledge and representation of the shared world are significantly different. When a shared basis of the environment is missing, communication between partners become more challenging. Language alone can be difficult and inefficient for partners to ground objects of interest. Motivated by previous empirical findings on eye gaze in joint attention, in collaboration, and in human language processing, our hypothesis is that eye gaze plays an important role in coordinating the collaborative referring process, especially between partners who have mismatched representations of their shared environment. Based on this hypothesis, the objective of this exploratory project is to examine the role of shared gaze in the collaborative referring process.&lt;br/&gt;&lt;br/&gt;This EArly Grant for Exploratory Research aims to generate new findings on how shared gaze coordinates the collaborative referring behaviors between partners with mismatched representation of the shared environment. These findings will provide insight to computational approaches and systems that combine gaze modeling with the collaborative discourse to ground references. The collected data will support many in-depth studies on language processing in situated dialogue.</AbstractNarration>
    <MinAmdLetterDate>08/13/2010</MinAmdLetterDate>
    <MaxAmdLetterDate>08/13/2010</MaxAmdLetterDate>
    <ARRAAmount/>
    <AwardID>1050004</AwardID>
    <Investigator>
      <FirstName>Joyce</FirstName>
      <LastName>Chai</LastName>
      <EmailAddress>jchai@cse.msu.edu</EmailAddress>
      <StartDate>08/13/2010</StartDate>
      <EndDate/>
      <RoleCode>Principal Investigator</RoleCode>
    </Investigator>
    <Institution>
      <Name>Michigan State University</Name>
      <CityName>East Lansing</CityName>
      <ZipCode>488242600</ZipCode>
      <PhoneNumber>5173555040</PhoneNumber>
      <StreetAddress>Office of Sponsored Programs</StreetAddress>
      <CountryName>United States</CountryName>
      <StateName>Michigan</StateName>
      <StateCode>MI</StateCode>
    </Institution>
    <ProgramElement>
      <Code>7495</Code>
      <Text>ROBUST INTELLIGENCE</Text>
    </ProgramElement>
    <ProgramReference>
      <Code>7495</Code>
      <Text>ROBUST INTELLIGENCE</Text>
    </ProgramReference>
    <ProgramReference>
      <Code>7916</Code>
      <Text>EAGER</Text>
    </ProgramReference>
  </Award>
</rootTag>
