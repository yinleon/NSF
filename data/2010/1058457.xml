<?xml version="1.0" encoding="UTF-8"?>

<rootTag>
  <Award>
    <AwardTitle>Ethics for Developing Technologies: An Analysis of Artficial Agent Technology</AwardTitle>
    <AwardEffectiveDate>04/15/2011</AwardEffectiveDate>
    <AwardExpirationDate>06/30/2014</AwardExpirationDate>
    <AwardAmount>213049</AwardAmount>
    <AwardInstrument>
      <Value>Continuing grant</Value>
    </AwardInstrument>
    <Organization>
      <Code>04050000</Code>
      <Directorate>
        <LongName>Directorate for Social, Behavioral &amp; Economic Sciences</LongName>
      </Directorate>
      <Division>
        <LongName>Division of Social and Economic Sciences</LongName>
      </Division>
    </Organization>
    <ProgramOfficer>
      <SignBlockName>Linda Layne</SignBlockName>
    </ProgramOfficer>
    <AbstractNarration>Moral notions and practices shape and are shaped by new technologies. Ethics for developing technologies involves identification and analysis of the ethical issues associated with a new technology in ways that can influence its design and use. Bringing ethical perspectives into the early stages of technological development is the best opportunity for those perspectives to have an influence.&lt;br/&gt;&lt;br/&gt;This project examines the discourse around artificial agent technology--computer systems that are described as autonomous decision-making entities--in order to understand how moral concepts and practices shape and are shaped by new technologies. Concepts of agency and autonomy are central to morality; they underpin the very possibility of morality and are strongly linked to concepts of responsibility and accountability. This project will examine how computer scientists and engineers conceptualize issues of responsibility with regard to artificial agents.&lt;br/&gt;&lt;br/&gt;The project will focus on two case studies: 1) the discussion centered around artificial moral agents, and 2) the discourse about autonomous military robots. The overarching descriptive research question for each case is: How are notions of responsibility, agency, and autonomy being negotiated? The overarching normative question is: How should artificial agents be conceptualized and designed? The methodology combines discourse analysis, philosophical analysis, and in-depth interviews with computer scientists and engineers. The project will have broader impact by training a postdoctoral fellow in ethics in science research and qualitative social science research methods. The results will be disseminated broadly to scholars as well as those who are engaged in the development of artificial agent technology.</AbstractNarration>
    <MinAmdLetterDate>04/06/2011</MinAmdLetterDate>
    <MaxAmdLetterDate>04/02/2012</MaxAmdLetterDate>
    <ARRAAmount/>
    <AwardID>1058457</AwardID>
    <Investigator>
      <FirstName>Deborah</FirstName>
      <LastName>Johnson</LastName>
      <EmailAddress>dgj7p@virginia.edu</EmailAddress>
      <StartDate>04/06/2011</StartDate>
      <EndDate/>
      <RoleCode>Principal Investigator</RoleCode>
    </Investigator>
    <Institution>
      <Name>University of Virginia Main Campus</Name>
      <CityName>CHARLOTTESVILLE</CityName>
      <ZipCode>229044195</ZipCode>
      <PhoneNumber>4349244270</PhoneNumber>
      <StreetAddress>P.O. BOX 400195</StreetAddress>
      <CountryName>United States</CountryName>
      <StateName>Virginia</StateName>
      <StateCode>VA</StateCode>
    </Institution>
    <ProgramElement>
      <Code>7603</Code>
      <Text>SCIENCE, TECH &amp; SOCIETY</Text>
    </ProgramElement>
    <ProgramReference>
      <Code>7915</Code>
      <Text>Ethics &amp; Values of SET</Text>
    </ProgramReference>
  </Award>
</rootTag>
