<?xml version="1.0" encoding="UTF-8"?>

<rootTag>
  <Award>
    <AwardTitle>HCC:Small: Tactile communication in human-computer Interactions</AwardTitle>
    <AwardEffectiveDate>08/15/2010</AwardEffectiveDate>
    <AwardExpirationDate>07/31/2013</AwardExpirationDate>
    <AwardAmount>500000</AwardAmount>
    <AwardInstrument>
      <Value>Standard Grant</Value>
    </AwardInstrument>
    <Organization>
      <Code>05020000</Code>
      <Directorate>
        <LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
      </Directorate>
      <Division>
        <LongName>Div Of Information &amp; Intelligent Systems</LongName>
      </Division>
    </Organization>
    <ProgramOfficer>
      <SignBlockName>Ephraim P. Glinert</SignBlockName>
    </ProgramOfficer>
    <AbstractNarration>Tactile communication systems represent a promising arena for enhancing human-computer interactions by using a relatively underused sensory system, the sense of touch, to present information. The goal of the proposed research is to understand how the sense of touch can be used to facilitate human-computer interactions by presenting information using tactile cues that is usually presented in the visual or auditory modalities. The tactile signals are similar to those produced by a vibrating cell phone or pager. One of the challenges in using a tactile display that has an array of vibrating motors distributed over the skin is in determining what type of information can be presented tactually, which aspects of vibrotactile stimulation can be used to convey this information effectively, and what tasks benefit from tactile cues. One objective of the proposed research is to develop a conceptual framework that provides guidance to computer-interface designers on how tactile communication systems can be created that reduce work load, decrease errors associated with information overload and diminish the time taken to complete tasks.&lt;br/&gt;&lt;br/&gt;The broader impact and application of this research extends well beyond computer interfaces, to all tactile interfaces that are used to display information to users, particularly those with visual and auditory impairments. Tactile displays are being developed to aid navigation in the visually impaired and to assist the hearing impaired in learning to lip read; the proposed research directly impacts the development of these displays by determining the optimal properties of vibrotactile signals that users can easily learn and identify. In addition to these applications, the present research is highly relevant to the implementation of tactile feedback in mobile devices and provides guidance as to the types of signals that are processed most efficiently by users.</AbstractNarration>
    <MinAmdLetterDate>08/01/2010</MinAmdLetterDate>
    <MaxAmdLetterDate>08/01/2010</MaxAmdLetterDate>
    <ARRAAmount/>
    <AwardID>1016998</AwardID>
    <Investigator>
      <FirstName>Lynette</FirstName>
      <LastName>Jones</LastName>
      <EmailAddress>LJones@MIT.edu</EmailAddress>
      <StartDate>08/01/2010</StartDate>
      <EndDate/>
      <RoleCode>Principal Investigator</RoleCode>
    </Investigator>
    <Institution>
      <Name>Massachusetts Institute of Technology</Name>
      <CityName>Cambridge</CityName>
      <ZipCode>021394301</ZipCode>
      <PhoneNumber>6172531000</PhoneNumber>
      <StreetAddress>77 MASSACHUSETTS AVE</StreetAddress>
      <CountryName>United States</CountryName>
      <StateName>Massachusetts</StateName>
      <StateCode>MA</StateCode>
    </Institution>
    <ProgramElement>
      <Code>7367</Code>
      <Text>Cyber-Human Systems (CHS)</Text>
    </ProgramElement>
    <ProgramReference>
      <Code>7923</Code>
      <Text>SMALL PROJECT</Text>
    </ProgramReference>
  </Award>
</rootTag>
